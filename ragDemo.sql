-- Connection: VectDB23.6 Vector - freepdb1
-- RAG Demo

select banner_full from v$version ;
select cloud_identity from v$containers ;
select sys_context('userenv', 'server_host') ; -- Should be db236

-- Cleanup environment
drop table VECTOR_STORE purge ;
drop table MY_BOOKS purge ; 
drop trigger trig_mybooks_vector_store_compound ;
drop function generate_text_response_gen ;

col file_name form A50
set pages 100


-- -------------------------------------------------------------------------
1. Create tables for Demo
-- -------------------------------------------------------------------------

create table MY_BOOKS (
   id INTEGER GENERATED BY 
      DEFAULT ON NULL AS IDENTITY  (START WITH 1 CACHE 20) PRIMARY KEY,
   file_name    VARCHAR2(900),
   file_size    INTEGER,
   file_type    VARCHAR2(100),
   file_content BLOB 
  ) LOGGING ; 


create table VECTOR_STORE (
   doc_id        NUMBER(*,0) NOT NULL ENABLE,
   chunk_id      NUMBER,
   chunk_data    VARCHAR2(4000 BYTE),
   chunk_vector  VECTOR,
     FOREIGN KEY (doc_id) REFERENCES MY_BOOKS(id)
  );


-- -------------------------------------------------------------------------
-- 2.a. Create LLM Credentials
-- -------------------------------------------------------------------------

BEGIN
  DBMS_NETWORK_ACL_ADMIN.APPEND_HOST_ACE (
    HOST         => 'api.openai.com',
    LOWER_PORT   => 443,
    UPPER_PORT   => 443,
    ACE          => xs$ace_type(
                   PRIVILEGE_LIST => xs$name_list('http'),
                   PRINCIPAL_NAME => 'VECTOR',
                   PRINCIPAL_TYPE => xs_acl.ptype_db
                 )
    );
END;
/

-- exec dbms_credential.drop_credential('OPENAI_CRED') ;

begin 
 dbms_vector_chain.create_credential (
    credential_name => 'OPENAI_CRED',
    params => json('{ "access_token": "sk-l...4cs"}') );
end ; 

-- -------------------------------------------------------------------------
-- 2.b. Verify the OpenAI LLM Access works (OPTIONAL)
-- -------------------------------------------------------------------------

set serveroutput on
declare
 model_params varchar2(4000) ; 
 inputQ clob;
 outputA clob;

begin
  model_params := '{ "provider": "openai", "credential_name": "OPENAI_CRED", "url": "https://api.openai.com/v1/chat/completions", "model": "gpt-4o-mini" }' ;
  inputQ := 'what is RAG?' ;
  outputA := dbms_vector_chain.utl_to_generate_text(inputQ, json(model_params));

  dbms_output.put_line(outputA);
end ;

-- -------------------------------------------------------------------------
-- 3. View Directory Locations
-- -------------------------------------------------------------------------

select substr(directory_name,1,20) dir_name,
       substr(directory_path,1,50) dir_path
from   all_directories ;


-- -------------------------------------------------------------------------
-- 4. Load PDF files into MY_BOOKS table 
-- -------------------------------------------------------------------------

insert into my_books (file_name, file_size, file_type, file_content)
   values ('23ai_Release_Notes.pdf', 
           dbms_lob.getlength(to_blob(bfilename('VEC_DUMP', '23ai_Release_Notes.pdf'))), 
           'PDF',
           to_blob(bfilename('VEC_DUMP', '23ai_Release_Notes.pdf'))
         );

insert into my_books (file_name, file_size, file_type, file_content)
   values ('database-free-installation-guide-linux.pdf', 
           dbms_lob.getlength(to_blob(bfilename('VEC_DUMP', 'database-free-installation-guide-linux.pdf'))), 
           'PDF',
           to_blob(bfilename('VEC_DUMP', 'database-free-installation-guide-linux.pdf'))
         );

commit;

select * from my_books ;


-- -------------------------------------------------------------------------
-- 5. Generate Embeddings from MY_BOOKS table
--    i. convert pdf to text
--   ii. chunk text data into manageable pieces
--  iii. generate vectors using specified embedding model  
-- -------------------------------------------------------------------------

INSERT INTO vector_store
   select mbk.id doc_id,
          emb.embed_id chunk_id,
          emb.embed_data chunk_data,
          to_vector(emb.embed_vector) chunk_embedding
   from   my_books mbk,
          dbms_vector_chain.utl_to_embeddings(
                        dbms_vector_chain.utl_to_chunks(dbms_vector_chain.utl_to_text(mbk.file_content),
--                        json('{"normalize":"all"}')),
                        json('{"by":"words", "max":"200", "split":"sentence", "normalize":"all"}')),
                        json('{"provider":"database", "model":"allMiniLML12"}')) t,
                        JSON_TABLE(t.column_value, '$[*]' COLUMNS (embed_id NUMBER PATH '$.embed_id',
                                   embed_data VARCHAR2(4000) PATH '$.embed_data', embed_vector CLOB PATH '$.embed_vector')) emb;

commit;

select * from vector_store order by doc_id,chunk_id ;


-- -------------------------------------------------------------------------
-- 6. Perform Similarity Search from Loaded documents 
-- -------------------------------------------------------------------------

-- Sample search strings:  "list some limitations" , "What has been deprecated" , "Is there anything new for ARM"

WITH query_vector AS (
 SELECT VECTOR_EMBEDDING(allMiniLML12 USING :search_string AS data) as embedding)
     SELECT chunk_id, chunk_data 
     FROM VECTOR_STORE, query_vector
ORDER BY VECTOR_DISTANCE (chunk_vector, query_vector.embedding, COSINE)
FETCH APPROX FIRST 4 ROWS ONLY;

-- same query - but display the source document 
WITH query_vector AS (
 SELECT VECTOR_EMBEDDING (allMiniLML12 USING :search_string AS data) as embedding)
     SELECT mb.file_name, vs.chunk_id, vs.chunk_data 
     FROM vector_store vs, my_books mb, query_vector
     WHERE vs.doc_id = mb.id
ORDER BY VECTOR_DISTANCE (vs.chunk_vector, query_vector.embedding, COSINE)
FETCH APPROX FIRST 4 ROWS ONLY;


-- -------------------------------------------------------------------------
-- 7. Create Function to Perform RAG operation with LLM 
-- -------------------------------------------------------------------------

CREATE OR REPLACE FUNCTION generate_text_response_gen(user_question VARCHAR2, doc_id number) 
 RETURN CLOB IS
   messages          CLOB;
   params_genai      CLOB;
   output            CLOB;
   message_line      VARCHAR2(4000);
   message_cursor    SYS_REFCURSOR;
   user_question_vec VECTOR;
   search_query      VARCHAR2(4000);

BEGIN
  -- vectorize the user question
  select to_vector(vector_embedding(allMiniLML12 USING user_question AS data)) as embedding
  into user_question_vec ;

  -- Open the cursor using the provided query string.
  search_query := 'SELECT CHUNK_DATA from VECTOR_STORE where doc_id ='||doc_id||' ORDER BY vector_distance(CHUNK_VECTOR, :user_question_vec, COSINE)'||
                  'FETCH FIRST 5 ROWS ONLY ' ;
  OPEN message_cursor FOR search_query USING user_question_vec; 

   messages:= '';

   -- Loop through cursor results and construct messages
   LOOP
      FETCH message_cursor INTO message_line;
      EXIT WHEN message_cursor%NOTFOUND;

      -- Append message line to message CLOB
      messages := messages || '("message": "' || message_line || '"},' || CHR(10);
   END LOOP ;

   -- Finally pass the user question
   messages := messages || '{ "Question": "' || user_question || '"},' || CHR(10);

   -- Close the cursor  CLOSE message_cursor;

   -- Remove the trailing comma and newline character
   messages := RTRIM(messages, ',' || CHR(10));

   -- Construct params JSON
   -- In order to use the OCI GenAI provider below we have precreated the credentials

   params_genai := '{ "provider": "openai", "credential_name": "OPENAI_CRED", "url": "https://api.openai.com/v1/chat/completions", "model": "gpt-4o-mini" }' ;

   -- These outputs can be uncommented for debugging purposes...
   -- dbms_output.put_line (messages);
   -- dbms_output.put_line(to_char(user_question_vec));

   -- Call UTL function to generate text
   output := dbms_vector_chain.utl_to_generate_text(messages, json(params_genai));
   dbms_output.put_line(output);

   -- Return the generated text
   RETURN output;

EXCEPTION
  WHEN OTHERS THEN
    RETURN SQLERRM || SQLCODE;
END;
/

-- Test the function
Select generate_text_response_gen(:search_string, 1) ; 

Select generate_text_response_gen('Hello', 1) ; 


-- -----------------------------------------------------------------------------
-- 8. Create a trigger to Embedding a PDF to store it in the VECTOR_STORE table 
-- -----------------------------------------------------------------------------

-- creates an embedding for the PDF and stores in the VECTOR_STORE

CREATE OR REPLACE TRIGGER trig_mybooks_vector_store_compound
FOR INSERT ON my_books
COMPOUND TRIGGER

   TYPE t_id_tab IS TABLE OF my_books.id%TYPE INDEX BY PLS_INTEGER;
   v_ids t_id_tab;

   AFTER EACH ROW IS
   BEGIN
      v_ids (v_ids.COUNT + 1) := :NEW.id;
   END AFTER EACH ROW;

   AFTER STATEMENT IS
   BEGIN
      FOR i IN 1..v_ids.COUNT LOOP
        INSERT INTO vector_store (doc_id, chunk_id, chunk_data, chunk_vector)

        SELECT mb.id AS doc_id, 
               et.chunk_id,
               et.chunk_data,
               to_vector(et.chunk_vector) AS chunk_vector
        FROM my_books mb
        CROSS JOIN TABLE (
           dbms_vector_chain.utl_to_embeddings ( 
              dbms_vector_chain.utl_to_chunks(
                 dbms_vector_chain.utl_to_text(mb.file_content ),
                    json('{"by":"words", "max":"200", "split":"sentence", "normalize":"all"}')
                  ),
                  json ('{"provider":"database", "model":"allMiniLML12"}')
              )
            ) t
        CROSS JOIN JSON_TABLE (
           t.column_value,
           '$[*]' COLUMNS (
              chunk_id     NUMBER         PATH '$.chunk_id', 
              chunk_data   VARCHAR2(4000) PATH '$.chunk_data',
              chunk_vector CLOB           PATH '$.chunk_vector'
             )
            ) AS et
            WHERE mb.id = v_ids(i);
       END LOOP;
    END AFTER STATEMENT;

END trig_mybooks_vector_store_compound;
/

commit ;
truncate table vector_store drop Storage ;
truncate table my_books drop storage ;

-- 
-- --------------------------------------------------------------------------------------------
-- Addendum Example: How to call an LLM from within an Oracle database

set serveroutput on

declare
  preferences clob;
  input clob;
  output clob;

begin

  preferences := '{
      "provider": "openai",
      "credential_name": "OPENAI_CRED",
      "url": "https://api.openai.com/v1/chat/completions",
      "model": "gpt-4o-mini"
     }';
  input := 'What is AI Camp?';

  output := dbms_vector_chain.utl_to_generate_text(input, json(preferences));
  dbms_output.put_line(output);

  if output is not null then
    dbms_lob.freetemporary(output);
  end if;
end;
/


